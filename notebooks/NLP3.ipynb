{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2b1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ee99a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('clean_Movie5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f22aab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Reviews3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>stuff going moment mj started listening music ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>nothe classic war worlds timothy hines enterta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Negative</td>\n",
       "      <td>starts manager nicholas bell giving welcome in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>must assumed praised nothe greatest filmed ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "      <td>superbly trashy wondrously unpretentious explo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>Negative</td>\n",
       "      <td>seems like consideration gone imdb reviews wen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>Negative</td>\n",
       "      <td>not believe made completely unnecessary first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>Negative</td>\n",
       "      <td>guy loser not get girls needs build picked str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>Negative</td>\n",
       "      <td>minute documentary buñuel made early spain poo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>Positive</td>\n",
       "      <td>saw child broke heart story unfinished ending ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 sentiment                                           Reviews3\n",
       "0               0  Positive  stuff going moment mj started listening music ...\n",
       "1               1  Positive  nothe classic war worlds timothy hines enterta...\n",
       "2               2  Negative  starts manager nicholas bell giving welcome in...\n",
       "3               3  Negative  must assumed praised nothe greatest filmed ope...\n",
       "4               4  Positive  superbly trashy wondrously unpretentious explo...\n",
       "...           ...       ...                                                ...\n",
       "24995       24995  Negative  seems like consideration gone imdb reviews wen...\n",
       "24996       24996  Negative  not believe made completely unnecessary first ...\n",
       "24997       24997  Negative  guy loser not get girls needs build picked str...\n",
       "24998       24998  Negative  minute documentary buñuel made early spain poo...\n",
       "24999       24999  Positive  saw child broke heart story unfinished ending ...\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89d3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = df['sentiment'].apply(lambda x: '1' if x == 'Positive' else ('0' if x == 'Negative' else 'neutral'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b645a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0','sentiment'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e1ee91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stuff going moment mj started listening music ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nothe classic war worlds timothy hines enterta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>starts manager nicholas bell giving welcome in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>must assumed praised nothe greatest filmed ope...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>superbly trashy wondrously unpretentious explo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>seems like consideration gone imdb reviews wen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>not believe made completely unnecessary first ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>guy loser not get girls needs build picked str...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>minute documentary buñuel made early spain poo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>saw child broke heart story unfinished ending ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Reviews3 Label\n",
       "0      stuff going moment mj started listening music ...     1\n",
       "1      nothe classic war worlds timothy hines enterta...     1\n",
       "2      starts manager nicholas bell giving welcome in...     0\n",
       "3      must assumed praised nothe greatest filmed ope...     0\n",
       "4      superbly trashy wondrously unpretentious explo...     1\n",
       "...                                                  ...   ...\n",
       "24995  seems like consideration gone imdb reviews wen...     0\n",
       "24996  not believe made completely unnecessary first ...     0\n",
       "24997  guy loser not get girls needs build picked str...     0\n",
       "24998  minute documentary buñuel made early spain poo...     0\n",
       "24999  saw child broke heart story unfinished ending ...     1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b77e80ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from prettytable import PrettyTable\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b432156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization of word \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wordnetlemma = WordNetLemmatizer()\n",
    "    def __call__(self, reviews):\n",
    "        return [self.wordnetlemma.lemmatize(word) for word in word_tokenize(reviews)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "854c48a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LemmaTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8312436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tokens'] = df['Reviews3'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17bb0d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews3</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stuff going moment mj started listening music ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stuff, going, moment, mj, started, listening,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nothe classic war worlds timothy hines enterta...</td>\n",
       "      <td>1</td>\n",
       "      <td>[nothe, classic, war, world, timothy, hines, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>starts manager nicholas bell giving welcome in...</td>\n",
       "      <td>0</td>\n",
       "      <td>[start, manager, nicholas, bell, giving, welco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>must assumed praised nothe greatest filmed ope...</td>\n",
       "      <td>0</td>\n",
       "      <td>[must, assumed, praised, nothe, greatest, film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>superbly trashy wondrously unpretentious explo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[superbly, trashy, wondrously, unpretentious, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>seems like consideration gone imdb reviews wen...</td>\n",
       "      <td>0</td>\n",
       "      <td>[seems, like, consideration, gone, imdb, revie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>not believe made completely unnecessary first ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[not, believe, made, completely, unnecessary, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>guy loser not get girls needs build picked str...</td>\n",
       "      <td>0</td>\n",
       "      <td>[guy, loser, not, get, girl, need, build, pick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>minute documentary buñuel made early spain poo...</td>\n",
       "      <td>0</td>\n",
       "      <td>[minute, documentary, buñuel, made, early, spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>saw child broke heart story unfinished ending ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[saw, child, broke, heart, story, unfinished, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Reviews3 Label  \\\n",
       "0      stuff going moment mj started listening music ...     1   \n",
       "1      nothe classic war worlds timothy hines enterta...     1   \n",
       "2      starts manager nicholas bell giving welcome in...     0   \n",
       "3      must assumed praised nothe greatest filmed ope...     0   \n",
       "4      superbly trashy wondrously unpretentious explo...     1   \n",
       "...                                                  ...   ...   \n",
       "24995  seems like consideration gone imdb reviews wen...     0   \n",
       "24996  not believe made completely unnecessary first ...     0   \n",
       "24997  guy loser not get girls needs build picked str...     0   \n",
       "24998  minute documentary buñuel made early spain poo...     0   \n",
       "24999  saw child broke heart story unfinished ending ...     1   \n",
       "\n",
       "                                                  Tokens  \n",
       "0      [stuff, going, moment, mj, started, listening,...  \n",
       "1      [nothe, classic, war, world, timothy, hines, e...  \n",
       "2      [start, manager, nicholas, bell, giving, welco...  \n",
       "3      [must, assumed, praised, nothe, greatest, film...  \n",
       "4      [superbly, trashy, wondrously, unpretentious, ...  \n",
       "...                                                  ...  \n",
       "24995  [seems, like, consideration, gone, imdb, revie...  \n",
       "24996  [not, believe, made, completely, unnecessary, ...  \n",
       "24997  [guy, loser, not, get, girl, need, build, pick...  \n",
       "24998  [minute, documentary, buñuel, made, early, spa...  \n",
       "24999  [saw, child, broke, heart, story, unfinished, ...  \n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50393cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\anush\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from gensim) (2.0.9)\n",
      "Requirement already satisfied: pandas in c:\\users\\anush\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.3)\n",
      "Requirement already satisfied: pyfume in c:\\users\\anush\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (0.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3.post1)\n",
      "Requirement already satisfied: simpful==2.12.0 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.12.0)\n",
      "Requirement already satisfied: fst-pso==1.8.1 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: miniful in c:\\users\\anush\\anaconda3\\lib\\site-packages (from fst-pso==1.8.1->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a168723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews3</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Review_Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stuff going moment mj started listening music ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stuff, going, moment, mj, started, listening,...</td>\n",
       "      <td>[-61.522743, 98.165985, 43.87292, 49.077736, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nothe classic war worlds timothy hines enterta...</td>\n",
       "      <td>1</td>\n",
       "      <td>[nothe, classic, war, world, timothy, hines, e...</td>\n",
       "      <td>[-7.450311, 27.769035, 18.905077, 15.507267, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>starts manager nicholas bell giving welcome in...</td>\n",
       "      <td>0</td>\n",
       "      <td>[start, manager, nicholas, bell, giving, welco...</td>\n",
       "      <td>[-68.85421, 52.91655, 25.118242, -19.980772, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>must assumed praised nothe greatest filmed ope...</td>\n",
       "      <td>0</td>\n",
       "      <td>[must, assumed, praised, nothe, greatest, film...</td>\n",
       "      <td>[-77.65243, 46.693996, 37.906998, 37.29187, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>superbly trashy wondrously unpretentious explo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[superbly, trashy, wondrously, unpretentious, ...</td>\n",
       "      <td>[-78.60378, 65.34709, -2.7407186, 20.885601, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>seems like consideration gone imdb reviews wen...</td>\n",
       "      <td>0</td>\n",
       "      <td>[seems, like, consideration, gone, imdb, revie...</td>\n",
       "      <td>[-18.400814, 17.781273, 4.7585373, 19.116325, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>not believe made completely unnecessary first ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[not, believe, made, completely, unnecessary, ...</td>\n",
       "      <td>[-41.02454, 44.665936, 32.92913, 22.206049, -2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>guy loser not get girls needs build picked str...</td>\n",
       "      <td>0</td>\n",
       "      <td>[guy, loser, not, get, girl, need, build, pick...</td>\n",
       "      <td>[-17.119638, 37.17709, -2.2863996, 9.641801, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>minute documentary buñuel made early spain poo...</td>\n",
       "      <td>0</td>\n",
       "      <td>[minute, documentary, buñuel, made, early, spa...</td>\n",
       "      <td>[-30.271288, 34.879288, 19.87128, 15.452813, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>saw child broke heart story unfinished ending ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[saw, child, broke, heart, story, unfinished, ...</td>\n",
       "      <td>[-14.404106, 17.902716, 11.924111, 11.128407, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Reviews3 Label  \\\n",
       "0      stuff going moment mj started listening music ...     1   \n",
       "1      nothe classic war worlds timothy hines enterta...     1   \n",
       "2      starts manager nicholas bell giving welcome in...     0   \n",
       "3      must assumed praised nothe greatest filmed ope...     0   \n",
       "4      superbly trashy wondrously unpretentious explo...     1   \n",
       "...                                                  ...   ...   \n",
       "24995  seems like consideration gone imdb reviews wen...     0   \n",
       "24996  not believe made completely unnecessary first ...     0   \n",
       "24997  guy loser not get girls needs build picked str...     0   \n",
       "24998  minute documentary buñuel made early spain poo...     0   \n",
       "24999  saw child broke heart story unfinished ending ...     1   \n",
       "\n",
       "                                                  Tokens  \\\n",
       "0      [stuff, going, moment, mj, started, listening,...   \n",
       "1      [nothe, classic, war, world, timothy, hines, e...   \n",
       "2      [start, manager, nicholas, bell, giving, welco...   \n",
       "3      [must, assumed, praised, nothe, greatest, film...   \n",
       "4      [superbly, trashy, wondrously, unpretentious, ...   \n",
       "...                                                  ...   \n",
       "24995  [seems, like, consideration, gone, imdb, revie...   \n",
       "24996  [not, believe, made, completely, unnecessary, ...   \n",
       "24997  [guy, loser, not, get, girl, need, build, pick...   \n",
       "24998  [minute, documentary, buñuel, made, early, spa...   \n",
       "24999  [saw, child, broke, heart, story, unfinished, ...   \n",
       "\n",
       "                                        Review_Embedding  \n",
       "0      [-61.522743, 98.165985, 43.87292, 49.077736, -...  \n",
       "1      [-7.450311, 27.769035, 18.905077, 15.507267, 2...  \n",
       "2      [-68.85421, 52.91655, 25.118242, -19.980772, 5...  \n",
       "3      [-77.65243, 46.693996, 37.906998, 37.29187, -1...  \n",
       "4      [-78.60378, 65.34709, -2.7407186, 20.885601, -...  \n",
       "...                                                  ...  \n",
       "24995  [-18.400814, 17.781273, 4.7585373, 19.116325, ...  \n",
       "24996  [-41.02454, 44.665936, 32.92913, 22.206049, -2...  \n",
       "24997  [-17.119638, 37.17709, -2.2863996, 9.641801, -...  \n",
       "24998  [-30.271288, 34.879288, 19.87128, 15.452813, -...  \n",
       "24999  [-14.404106, 17.902716, 11.924111, 11.128407, ...  \n",
       "\n",
       "[25000 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "#skip-gram\n",
    "modelw = Word2Vec(sentences=df['Tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "df['Review_Embedding'] = df['Tokens'].apply(\n",
    "    lambda tokens: sum(modelw.wv[token] for token in tokens if token in modelw.wv)\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c91f4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Prepare features (embeddings) and labels\n",
    "x = np.array(df['Review_Embedding'].tolist())  # Embeddings as feature matrix\n",
    "y = np.array(df['Label'])  # Sentiment labels\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c03031a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anush\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lmodel = LogisticRegression()\n",
    "lmodel.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lmodel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7a9d186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test dataset: 0.8536\n",
      "Precision Score on test: 0.8536\n",
      "AUC Score on test: 0.9215564290993448\n",
      "F1 Score: 0.8535655534870275\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test dataset: %s\" % accuracy_score(y_test,lmodel.predict(x_test)))\n",
    "print(\"Precision Score on test: %s\" % precision_score(y_test,lmodel.predict(x_test),average='micro'))\n",
    "print(\"AUC Score on test: %s\" % roc_auc_score(y_test,lmodel.predict_proba(x_test)[:,1],multi_class='ovo',average='macro'))\n",
    "f1_score_4 =f1_score(y_test,lmodel.predict(x_test),average=\"weighted\")\n",
    "print(\"F1 Score: %s\" % f1_score_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeb79720",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(x_train, y_train)\n",
    "y_pred_rf = rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56047df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train dataset for Random forest classifier: 1.0\n",
      "Precision Score on training dateset for Random Forest Classifier: 1.0\n",
      "AUC Score on training dateset for Random Forest Classifier: 1.0\n",
      "F1 Score training dateset for Random Forest Classifier: 1.0\n",
      "Accuracy on test dataset for Random forest classifier: 0.8168\n",
      "Precision Score on test for Random Forest Classifier: 0.8168\n",
      "AUC Score on test for Random Forest Classifier: 0.8957168566056375\n",
      "F1 Score for Random Forest Classifier: 0.8167056648527239\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on train dataset for Random forest classifier: %s\" % accuracy_score(y_train,rf_model.predict(x_train)))\n",
    "print(\"Precision Score on training dateset for Random Forest Classifier: %s\" % precision_score(y_train,rf_model.predict(x_train),average='micro'))\n",
    "print(\"AUC Score on training dateset for Random Forest Classifier: %s\" % roc_auc_score(y_train,rf_model.predict_proba(x_train)[:,1],multi_class='ovo',average='macro'))\n",
    "f1_score_train_4 =f1_score(y_train,rf_model.predict(x_train),average=\"weighted\")\n",
    "print(\"F1 Score training dateset for Random Forest Classifier: %s\" % f1_score_train_4)\n",
    "print(\"Accuracy on test dataset for Random forest classifier: %s\" % accuracy_score(y_test,rf_model.predict(x_test)))\n",
    "print(\"Precision Score on test for Random Forest Classifier: %s\" % precision_score(y_test,rf_model.predict(x_test),average='micro'))\n",
    "print(\"AUC Score on test for Random Forest Classifier: %s\" % roc_auc_score(y_test,rf_model.predict_proba(x_test)[:,1],multi_class='ovo',average='macro'))\n",
    "f1_score_4 =f1_score(y_test,rf_model.predict(x_test),average=\"weighted\")\n",
    "print(\"F1 Score for Random Forest Classifier: %s\" % f1_score_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9583e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred = dt_model.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b17cdeae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train dataset: 1.0\n",
      "Precision Score on training dateset: 1.0\n",
      "AUC Score on training dateset: 1.0\n",
      "F1 Score training dateset: 1.0\n",
      "Accuracy on test dataset: 0.7072\n",
      "Precision Score on test: 0.7072\n",
      "AUC Score on test: 0.707143564612292\n",
      "F1 Score: 0.707180508038437\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on train dataset: %s\" % accuracy_score(y_train,dt_model.predict(x_train)))\n",
    "print(\"Precision Score on training dateset: %s\" % precision_score(y_train,dt_model.predict(x_train),average='micro'))\n",
    "print(\"AUC Score on training dateset: %s\" % roc_auc_score(y_train,dt_model.predict_proba(x_train)[:,1],multi_class='ovo',average='macro'))\n",
    "f1_score_train_4 =f1_score(y_train,dt_model.predict(x_train),average=\"weighted\")\n",
    "print(\"F1 Score training dateset: %s\" % f1_score_train_4)\n",
    "print(\"Accuracy on test dataset: %s\" % accuracy_score(y_test,dt_model.predict(x_test)))\n",
    "print(\"Precision Score on test: %s\" % precision_score(y_test,dt_model.predict(x_test),average='micro'))\n",
    "print(\"AUC Score on test: %s\" % roc_auc_score(y_test,dt_model.predict_proba(x_test)[:,1],multi_class='ovo',average='macro'))\n",
    "f1_score_4 =f1_score(y_test,dt_model.predict(x_test),average=\"weighted\")\n",
    "print(\"F1 Score: %s\" % f1_score_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
